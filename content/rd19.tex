% Vector variables (in Bold Font style)
\newcommand{\va}{\mathbf{a}} \newcommand{\vb}{\mathbf{b}} \newcommand{\vc}{\mathbf{c}} \newcommand{\vd}{\mathbf{d}} \newcommand{\ve}{\mathbf{e}} \newcommand{\vf}{\mathbf{f}} \newcommand{\vg}{\mathbf{g}} \newcommand{\vh}{\mathbf{h}} \newcommand{\vi}{\mathbf{i}} \newcommand{\vj}{\mathbf{j}} \newcommand{\vk}{\mathbf{k}} \newcommand{\vl}{\mathbf{l}} \newcommand{\vm}{\mathbf{m}} \newcommand{\vn}{\mathbf{n}} \newcommand{\vo}{\mathbf{o}} \newcommand{\vp}{\mathbf{p}} \newcommand{\vq}{\mathbf{q}} \newcommand{\vr}{\mathbf{r}} \newcommand{\vs}{\mathbf{s}} \newcommand{\vt}{\mathbf{t}} \newcommand{\vu}{\mathbf{u}} \newcommand{\vv}{\mathbf{v}} \newcommand{\vw}{\mathbf{w}} \newcommand{\vx}{\mathbf{x}} \newcommand{\vy}{\mathbf{y}} \newcommand{\vz}{\mathbf{z}} 
\newcommand{\vA}{\mathbf{A}} \newcommand{\vB}{\mathbf{B}} \newcommand{\vC}{\mathbf{C}} \newcommand{\vD}{\mathbf{D}} \newcommand{\vE}{\mathbf{E}} \newcommand{\vF}{\mathbf{F}} \newcommand{\vG}{\mathbf{G}} \newcommand{\vH}{\mathbf{H}} \newcommand{\vI}{\mathbf{I}} \newcommand{\vJ}{\mathbf{J}} \newcommand{\vK}{\mathbf{K}} \newcommand{\vL}{\mathbf{L}} \newcommand{\vM}{\mathbf{M}} \newcommand{\vN}{\mathbf{N}} \newcommand{\vO}{\mathbf{O}} \newcommand{\vP}{\mathbf{P}} \newcommand{\vQ}{\mathbf{Q}} \newcommand{\vR}{\mathbf{R}} \newcommand{\vS}{\mathbf{S}} \newcommand{\vT}{\mathbf{T}} \newcommand{\vU}{\mathbf{U}} \newcommand{\vV}{\mathbf{V}} \newcommand{\vW}{\mathbf{W}} \newcommand{\vX}{\mathbf{X}} \newcommand{\vY}{\mathbf{Y}} \newcommand{\vZ}{\mathbf{Z}} 
% Greek Vector variables (in Bold Font style)
\newcommand{\vbeta}{\bm{\beta}} 
\newcommand{\vbhat}{\bm{\hat \beta}}
\newcommand{\vbstar}{\bm{\beta^*}}
\newcommand{\veps}{\bm{\epsilon}}
\newcommand{\vmu}{\bm{\mu}}
\newcommand{\vtheta}{\bm{\theta}}
\newcommand{\valpha}{\bm{\alpha}}
\newcommand{\vdelta}{\bm{\delta}}

% Constant vectors
\newcommand{\vzero}{\mathbf{0}}
\newcommand{\vone}{\mathbf{1}}
\newcommand{\thetac}{\mathrm{\theta^{(0)}}}
\newcommand{\abs}[1]{|{#1}|}
\newcommand{\norm}[1]{\|#1\|_2} % l2 norm for ordinary vectors

% Scalars

% Matrix variables (in DS style where possible)
\newcommand{\mA}{\mathds{A}} \newcommand{\mB}{\mathds{B}} \newcommand{\mC}{\mathds{C}} \newcommand{\mD}{\mathds{D}} \newcommand{\mE}{\mathds{E}} \newcommand{\mF}{\mathds{F}} \newcommand{\mG}{\mathds{G}} \newcommand{\mH}{\mathds{H}} \newcommand{\mI}{\mathds{I}} \newcommand{\mJ}{\mathds{J}} \newcommand{\mK}{\mathds{K}} \newcommand{\mL}{\mathds{L}} \newcommand{\mM}{\mathds{M}} \newcommand{\mN}{\mathds{N}} \newcommand{\mO}{\mathds{O}} \newcommand{\mP}{\mathds{P}} \newcommand{\mQ}{\mathds{Q}} \newcommand{\mR}{\mathds{R}} \newcommand{\mS}{\mathds{S}} \newcommand{\mT}{\mathds{T}} \newcommand{\mU}{\mathds{U}} \newcommand{\mV}{\mathds{V}} \newcommand{\mW}{\mathds{W}} \newcommand{\mX}{\mathds{X}} \newcommand{\mY}{\mathds{Y}} \newcommand{\mZ}{\mathds{Z}}

\newcommand{\cA}{\mathcal{A}} \newcommand{\cB}{\mathcal{B}} \newcommand{\cC}{\mathcal{C}} \newcommand{\cD}{\mathcal{D}} \newcommand{\cE}{\mathcal{E}} \newcommand{\cF}{\mathcal{F}} \newcommand{\cG}{\mathcal{G}} \newcommand{\cH}{\mathcal{H}} \newcommand{\cI}{\mathcal{I}} \newcommand{\cJ}{\mathcal{J}} \newcommand{\cK}{\mathcal{K}} \newcommand{\cL}{\mathcal{L}} \newcommand{\cM}{\mathcal{M}} \newcommand{\cN}{\mathcal{N}} \newcommand{\cO}{\mathcal{O}} \newcommand{\cP}{\mathcal{P}} \newcommand{\cQ}{\mathcal{Q}} \newcommand{\cR}{\mathcal{R}} \newcommand{\cS}{\mathcal{S}} \newcommand{\cT}{\mathcal{T}} \newcommand{\cU}{\mathcal{U}} \newcommand{\cV}{\mathcal{V}} \newcommand{\cW}{\mathcal{W}} \newcommand{\cX}{\mathcal{X}} \newcommand{\cY}{\mathcal{Y}} \newcommand{\cZ}{\mathcal{Z}}

\newcommand{\ewise}[2]{{#1 * #2}} % element-wise product
\newcommand{\EE}{\mathrm{E}} % Expectation
\newcommand{\g}{\,\vert\,} % for conditional probability, division
\newcommand{\set}[1]{\{{#1}\}}
\newcommand{\size}[1]{\mathrm{\#}(#1)}

\section {A fully connected FFNN} \label {sec: fcffnn}
Forward propagation
\begin {equation} \begin {split}
& \text {Initialize the input layer } \vZ^1 = \vX, \vA^1 = \vZ^1 \\
& \text {Propagate all activity forward } \vZ^l = \mW^l \vA^{l-1} + \vB^l, \vA^l = f^l(\vZ^l) \\
\end {split} \end {equation}

$\vZ^l = \mW^l \vA^{l-1} + \vB^l$ is equivalent to 
\begin{equation} \label {eq: nnwts}
\begin{bmatrix}
Z_1 \\
\ldots \\
Z_J \\
\end{bmatrix}
= 
\begin{bmatrix}
W_{1,1} & \ldots & W_{1,K} \\
\ldots & \ldots & \ldots \\
W_{J,1} & \ldots & W_{J,K} \\
\end{bmatrix}
\begin{bmatrix}
A_1 \\
\ldots \\
A_K \\
\end{bmatrix} 
+
\begin{bmatrix}
B_1 \\
\ldots \\
B_J \\
\end{bmatrix}
\end{equation}
Where layer $l$ has $J$ nodes and layer $l-1$ has $K$ nodes.

Backward propagation
\begin {equation} \begin {split}
& \text {Assuming that the loss function is } \cL = 0.5 (\vY - \vA^L)^2 \\
& \qquad \text {Where $\vY$ is the known output corresponding to the input $\vX$} \\
& \qquad \text {Calculate the final error } \nabla_a \cL =  \vA^L - \vY \\
& \text {Initialize  the back propagation } \vdelta^L =  \ewise {\nabla_a \cL} {{f^L}^{'} (\vZ^L)} \\
& \text {Backpropagate the error } \vdelta^l =  \ewise {\left[ {\mW^{l+1}}^T \vdelta^{l+1} \right]} {{f^{l}}^{'} (\vZ^l)}, l \in [2, L-1] \\
& \text {Calculate the gradient of weights } \frac {\partial \cL} {\partial \mW^l} = \vdelta^l {\vA^{l-1}}^T, l \in [2, L] \\
& \qquad \text {Equivalently } \frac {\partial \cL} {\partial W_{j,k}^l} = a_k^{l-1} \delta_j^l, l \in [2, L] \\
& \text {Calculate the gradient of bias weights } \frac {\partial \cL} {\partial \vB^l} = \vdelta^l, l \in [2, L] \\
& \qquad \text {Equivalently } \frac {\partial \cL} {\partial B_j^l} = \delta_j^l, l \in [2, L] \\
\end {split} \end {equation}

Update ($\eta$ is a hyperparameter that is not learned by the FFNN)
\begin {equation} \begin {split}
& \text {Update weights } \mW^l = \mW^l - \eta \frac {\partial \cL} {\partial \mW^l}, l \in [2, L] \\
& \text {Update bias weights } \vB^l = \vB^l - \eta \frac {\partial \cL} {\partial \vB^l}, l \in [2, L] \\
\end {split} \end {equation}

\section {Geometry tips}
\begin {enumerate}
\item Commit to memory, that the shortest unsigned distance between a point $\vx_0$ and a hyperplane $\vtheta^T \vx + \thetac = 0$ is $\frac {\abs{\vtheta^T \vx_0 + \thetac}} {\norm{\theta}}$
\end {enumerate}

\section {Tips for solving perceptron problems}
\begin {enumerate}
\item Commit to memory that when hinge loss ($L_h(z)$) $> 0$, then the gradient of the hinge loss is $-z$
  \begin {enumerate}
  \item When hinge loss for a data point $\vx_i, y_i$ and hyperplane $\vtheta^T \vx_i + \thetac = 0$ is given to be $> 0$, 
  \item Then $\max(0, 1 - y_i(\vtheta^T \vx_i + \theta)) > 0 \implies L_h = 1 - y_i(\vtheta^T \vx_i + \theta)$
  \item And the gradient of $L_h$ wrt $\vtheta$ is $- y_i \vx_i$
  \end {enumerate}
\item Commit to memory that the form of a hyperplane is $\vtheta^T \vx + \thetac = 0$
  \begin {enumerate}
  \item If the points are linearly separable then the positive margin boundary is given by $\vtheta^T \vx + \thetac = 1$; $\vtheta, \thetac$ remain unchanged from the decision boundary
  \item Similarly, the negative margin boundary is given by $\vtheta^T \vx + \thetac = -1$
  \end {enumerate}
\end {enumerate}

\section {Tips for solving SVM and nonlinear classification problems}
\begin {enumerate}
\item SVM
  \begin {enumerate}
  \item When a new training sample is introduced into a linearly separable training set of $n$ samples with $k$ support vectors, the new SVM may have as many as $n+1$ support vectors. This is because the SVM may completly reconfigure as it determines a new decision boundary that supports the two classes. The previous statement assumes that the training set with $n+1$ samples remains linearly separable
  \end {enumerate}
\item Regularization
  \begin {enumerate}
  \item Regularizing the offset (bias, $\thetac$) parameter forces a decision boundary that goes through the origin
  \item In a two-feature space, regularizing only the coefficient of the first feature ($x_1$, on the x-axis), forces the coefficient to be close to $0$. I.e. the decision boundary becomes horizontal to the x-axis
  \item On the other hand if only the coefficient of the second feature is regularized, the decision boundary becomes vertical to the x-axis because the coefficient of $x_2$ goes to $0$
  \end {enumerate}
\end {enumerate}

\section {Tips for solving Clustering problems}
\begin {enumerate}
\item While K-means usually means L2-norm as the distance metric, it is possible to run K-means with other distance metrics such as L1-norm
\item K-means, K-medoid problems can be solved by hand using excel; however they may also be solvable by modeling the problem as hard clustering with e-step and m-step in Rstudio
\item EM calcuations can be done by hand inside Rstudio. One can use R's dnorm() function to calculate the probability density of the gaussian components
\item In the EM algorithm, the e-step takes into account the weights of the initialized classes
  \begin {enumerate}
  \item If all the classes are initialized identically with the exception of the weights, then the only item that makes a difference in the e-step is the weight of each class
  \end {enumerate}
\item The EM algorithm is only guaranteed to find the parameters that produce the ``highest lower bound'' of log-likelihood. It does not actually find the parameters for the ``highest likelihood''
\end {enumerate}

\section {Tips for solving Neural Network Problems}
\begin {enumerate}
\item If the problem involves forward propagation in a feed forward neural network, consider coding the variables in Rstudio so that the process of matrix multiplication is straightforward (using R's matrix multiplication)
\item The sigmoid function is available in wolfram alpha, but not (in a straightforward manner) in Rstudio
\item For RNN/LTSM computation, consider using excel where the column headers are the names of all the variables and each row contains timesteps. Timesteps may begin at $-1$ or $0$ to designate the initialization step. Input $x$ values are only fed in after the initialization step
\item To solve linear separation problems in two dimensions, it is helpful to plot the points on a two-dimensional chart using the desmos calculator
\item A (convolution) filter matrix applied to a portion of a larger matrix (the image) produces a single number. This number corresponds to the element wise multiplication of the two matrices followed by a sum of the result
\end {enumerate}

\section {Tips for solving Reinforcement learning problems}
\begin {enumerate}
\item For problems involving multiple states, transition probabilities and rewards, but a small number of actions, consider modeling all the tables in excel
\item For problems involving diagrams that are used to represent the actions (usually more than two) but a simple reward and transition probability structure, consider drawing a diagram for each iteration of the algorithm
\item In RL/MDP problems that use discounted rewards, the first step is not to be discounted.
  \begin {enumerate}
  \item Discounting starts only from the second time step
  \item If taking a step has a cost and leads to a cell with a reward, the two rewards should be added before applying the discount
  \item Thus the reward streams looks as: reward-for-being-in-starting-state + discount * (reward-for-taking-step + reward-for-being-in-next-state) + discount * discount ( )
  \end {enumerate}
\item Commit to memory that $T(s, a, s^{'})$ is the probability of getting to state $s^{'}$ from state $s$ on action $a$
\item Commit to memory that each iteration of the Value Iteration algorithm can involve the update of $O(\size{S} \size {S} \size{A})$ entries
\item Commit to memory that for Q-learning (based on real-world samples), $\max_{a^{'}} Q_k(s^{'}, a^{'})$ when there is only one action, is just $Q_k(s^{'}, a^{'})$. Remember that $s^{'}$ refers to the neighboring state
\end {enumerate}

\section {14.310}
\subsection {Diff-in-Diff analysis}
The Diff-in-Diff approach is used to estimate the effect of a treatment using natural experiments. Often it is not possible to treat subjects. However a natural experiment may treat a collection of subjects some of whom are in the control group and some in the treatment g
roup. Membership in the control and treatment group is independent of the event and depends on other natually occurring factors.

Definitions:
\begin {enumerate}
\item $Y_{i, e}$ is the response observation for the ith sample, before ($e = 0$) or after the event ($e = 1$)
\item $T_i$ are categorical variables and $T_i \in \set{0, 1}$. $T_i = 1$ when subject is in the treatment group.  $T_i = 0$ when subject is in the control group
\item $E_e = 1$ for the observations that are after an event has happened and $0$ otherwise. The event applies to both the treatment and control groups and is the equivalent of applying the treatment to both the treatment and control groups
\end {enumerate}

Ordinary Least Squares (OLS) equation:
\begin {equation} \begin {split} 
& Y_{i, e} = \beta_0 + \beta_1 T_i + \beta_2 E_e + \beta_3 T_i E_e + \epsilon_{i, e} \\
& \text {Where $\epsilon_{i, e}$ is the unexplained noise} \\
\end {split} \end {equation}

Interpretation:
\begin {enumerate}
\item $\beta_0$: the average value of $Y_{i, e}$ when $T_i = 0, E_e = 0$
\item $\beta_1$: the average increase in $Y_{i, e}$ from $T_i = 0, E_e = 0$ to $T_i = 1, E_e = 0$
\item $\beta_2$: the average increase in $Y_{i, e}$ from $T_i = 0, E_e = 0$ to $T_i = 0, E_e = 1$
\item $\beta_3$: the average causal effect on $Y$ of being treated. This is the diff-in-diff estimate
\item The difference in average outcome in the treatment group before and after treatment is $(\beta_0 + \beta_1 + \beta_2 + \beta_3) - (\beta_0 + \beta_1) = \beta_3 + \beta_2$
\item The difference in average outcome in the control group before and after treatment is $(\beta_0 + \beta_2) - (\beta_0) = \beta_2$
\item Thus, the difference in differences is $(\beta_3 + \beta_2) - (\beta_2) = \beta_3$
\item The diff-in-diff estimate is obtained by removing the effect of the event represented by $E$ on the control group from the effect of the event represented by $E$ on the treatment group
\end {enumerate}

Remarks:
\begin {enumerate}
\item The Diff-in-Diff relies on a "parallel trends" assumption
\item The parallel trends is stated as "in the absence of treatment, the difference between the ‘treatment’ and ‘control’ group is constant over time."
\end {enumerate}

\subsection {ATE and Selection Bias} 
When we observe a group of subjects, some of whom have been treated and some not, we calculate
\begin {equation} \begin {split}
& \EE(Y_i(1) \g  W_i = 1) - \EE(Y_i(0) \g  W_i = 0) \iff \\
& [ \EE(Y_i(1) \g  W_i = 1) -  \EE(Y_i(0) \g  W_i = 1) ] +  \\
& \qquad \EE(Y_i(0) \g  W_i = 1) -  \EE(Y_i(0) \g  W_i = 0) ] \iff  \\
& \text {Average Treatment Effect} + \text { Selection Bias} \\
\end {split} \end {equation}

\subsection {Sample size}
The sample size required to achieve a certain power is given by:
\begin {equation} \begin {split}
& N = \frac {\left(\Phi^{-1} (1 - \beta) + \Phi^{-1} (1 - \alpha/2) \right)^2} {\frac {\tau^2} {\sigma^2} \gamma (1 - \gamma)} \\
& \beta \equiv \text { probability of type II error} \\
& 1 - \beta \equiv \text { power} \\ 
& \alpha \equiv \text { significance level desired for a two-sided test} \\
& \gamma \equiv \text { fraction of sample in treatment group} \\
& \tau \equiv \text { ATE} \\
\end {split} \end {equation}

$N$ may have to be rounded up (if it is fraction) in order to obtain a conservative estimate of sample size.

\subsection {F Stat}
\begin {enumerate}
\item $SSRu := $ Sum of squared residuals of unrestricted model
\item $SSRr := $ Sum of squared residuals of restricted model
\item $r := $ number of restrictions
\item $k := $ number of covariates
\item $n := $ number of samples
\item $F_{stat} := \frac {\frac {SSRr - SSRu} {r}} {\frac {SSRu} {n - (k+1)}}$. When $F_{stat}$ is large, the null hypothesis can be rejected
\item $F_{stat} \sim F(r, n-(k+1))$ where $F(df1, df2)$ is the F-distribution with $(df1, df2)$ degrees of freedom
\end {enumerate}

\subsection {Fixed effects model} \label {r: fem}
G(factor(admin)) creates a dummy variable, one per region, and includes the dummy variable
in the regression
\begin{lstlisting}[language=R]
library("lfe")
model2 <- felm(sex ~ teasown + post + teapost + 
G(factor(admin)), data = qiandata)
summary(model2)
\end{lstlisting}

\subsection {Instrument variable regression}
To use the ivreg() function directly one needs to setup the call as
\begin{lstlisting}[language=R]
ivreg (y ~ exogenous_vars + endogenous_var | 
exogenous_vars + instrument_var)
\end{lstlisting}

\subsection {Fisher exact test in R}
\begin{lstlisting}[language=R]
library(perm)
rm(list = ls())
cough_severity = matrix(c(3, 5, 0, 4, 0, 1), nrow=6, ncol=1, byrow=TRUE)
cough_severity
n_treatment = 3
n_control = 3
n = n_treatment + n_control

permutations = chooseMatrix(n, n_treatment)
permutations
num_permutations = nrow(permutations)

treatment_avg = (1/n_treatment)* permutations %*%cough_severity

control_avg = (1/n_control)*(1-permutations)%*%cough_severity

test_statistic =  abs(treatment_avg-control_avg)

actual_obs_row = 20
observed_test_statistic = test_statistic[actual_obs_row]

by_chance = (test_statistic >= observed_test_statistic)
total_by_chance = sum(by_chance)
\end{lstlisting}
